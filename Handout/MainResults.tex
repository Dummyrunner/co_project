\subsection{Concept of Barrier Methods}
Convex optimization Problems with no inequality constraints can  be solved efficiently by using Newton's method. If inequality constraints are involved, Newton's method can not guarantee feasibiliy of a solution. It is hence desirable, to transform an inequality-constrained optimization problem into a only equality-constrained one. Therefore, we move the inequality constraints implicitley to the objective function.
%TODO improve sentence
\todo A simple and also precise way to do this, evaluate an  indicator function  
\begin{align}
	\ifct (x) :=
	\begin{cases}
		0 \quad &\text{for } u \neq 0\\
		\infty &\text{for } u > 0
	\end{cases}
\end{align}
on the values of the inequality constraints $ f_i, i=1,\dots,m $. Then, the optimization Problem has the shape
\begin{align}
	\begin{aligned}
	& \underset{x}{\text{minimize}}
	& & f_0(x) + \sum_{i=1}^{m} \ifct(f_i(x))\\
	& \text{subject to}
	& & \Aeq x - \beq = 0, \; i = 1,\dots, p.
	\end{aligned} \label{eq:ifctProblem}
\end{align}
This problem is an equivalent to \eqref{eq:OptProblem} and has no inequality constraints. However, it is clearly neither convex nor continuous (and hence not differentiable). Since we need these properties to solve the optimization problem computationally, we approximate the indicator function $ \ifct $ by the function
\begin{equation}
	\ifcthat (u) =
	\begin{cases}
	 \frac{1}{t}\log(-u) \quad \text{for } u < 0,\\
	 \infty \quad \text{for } u\geq 0,
	\end{cases}
\end{equation}
The parameter $ t>0 $ sets the approximation's accuracy. The higher $ t $ is, the better the indicator function is approximated.
By replacing the Indicator functions by $ \ifcthat $, we obtain an
%TODO evt plot von Ihat einfügen!100% 100
%TODO Mentioan bad numeric condition for high
approximation 
\begin{equation}
\begin{aligned}
& \underset{x}{\text{minimize}}
& & f_0(x) - \sum_{i=1}^{m} \frac{1}{t} \log(-f_i(x)) \\
& \text{subject to}
& & \Aeq x - \beq = 0
\end{aligned} \label{eq:ApproxProblem}
\end{equation}
of problem \eqref{eq:OptProblem}.

Note, that $ \frac{1}{t}\log(-u) $ is convex, increasing in $ u $, and differentiable on the feasible set. Hence the entire function $ \sum_{i=1}^{m} \ifcthat(f_i(x)) $ is convex and \eqref{eq:ApproxProblem} is a convex Problem with differentiable objective function. These properties allow us to solve $ \eqref{eq:ApproxProblem} $ computationally.
We call an optimal point $ \xopt(t) $ of \eqref{eq:ApproxProblem} with parameter $ t $  a central point and a solution to its dual problem $ (\lambdaopt(t),\nuopt(t)) $ a dual central point. The set of (dual) solutions of \eqref{eq:ApproxProblem} for all $ t>0 $ we call the (dual) central path.
One can show, that solutions $ (\xoptt,\lambdaoptt,\nuoptt) $ of \eqref{eq:ApproxProblem} converge to the solution  $ (\xopt,\lambdaopt, \nuopt) $ of \eqref{eq:OptProblem} for $ t  \longrightarrow 0 $. The proof is shown in \cite{BV}.
\label{sec:BarrierConcept}
\subsection{Measure for the Approximation's quality}
An immediately arising question is, what conclusions about the solution $ (\xopt,\lambdaopt, \nuopt) $ of \eqref{eq:OptProblem} can be drawn from a knowing a solution of $ \eqref{eq:ApproxProblem} $ for a certain $ t>0 $. 
By \todo
%TODO check if really right!
argumenting with the Lagrangian and the Saddlepoint-theorem, one can show that the inequality
\[ \fnull (\xoptt) - \popt \leq \frac{m}{t}\] holds, where $ t $ is the parameter of the approximative indicator-function $ \ifcthat $ and $ m $ the number of inequality constraints as defined above. This means, that the optimum $ \xoptt $ approximated problem \eqref{eq:ApproxProblem} has an objective value $ \fnull(\xoptt) $ that is maximally by $ \frac{m}{t} $ larger (and hence worse) than the real optimal value $ \popt $ of the original problem. Thus, one can theoretically force a desired bound on the subobtimality $ \epsilon >0 $ by just choosing $ t $ large enough, in particular $ t := \frac{m}{\epsilon} $. However, just solving \eqref{eq:ApproxProblem} with a large choice of $ t $ does not work out in general, since numerical issues can make convergence of Newton's Method dependent on the choice of the initial point $ \xnull $.
\label{sec:approxMeasure}

\subsection{Algorithmic Use of the Barrier Concept}
As already mentioned in section \ref{sec:approxMeasure}, one can not in general solve  \eqref{eq:ApproxProblem} without a good guess at the initial value $ \xnull $. So how to make use of the barrier concept? The idea of interior methods is to find points along the problem's central path. Two methods are introduced in the following. Emphasis of the explanations as well as the implementation in \matlab \ will be on the Primal-Dual Interior Point Method.
\subsubsection{Interior Point Method with Full Newton Search}
As mentioned before, for large $ t $ a good initial point $ \xnull $, meaning an initial point that is not far away from the actual minimum of \eqref{eq:OptProblem} is crucial for avoiding large numerical errors. This can be achieved by starting with optimization of \eqref{eq:ApproxProblem} for small $ t=t_1 $, which leads to a a rather bad approximation of the original problem, but also to better numerical behavior. After finding $ \xopt(t_1) $ via Newton's method, $ t $ is increased to $ t= t_2 > t_1 $ by a certain rate and  \eqref{eq:ApproxProblem} is solved again with parameter $ t = t_2 $, with choice $ \xnull = \xopt(t_1) $ for the initial point.
%For step $ n $ of the algorithm call finding $ \xoptt $ the centering, or outer iteration, step of the algorithm and increasing $ t_n \mapsto t_{n+1} $ with setting $ \xnull :=  \xopt(t_n)$ an outer iteration.
For step $ n $ of the algorithm call finding $ \xoptt $ the centering, and updating and updating $ t $ and $ \xoptt $ an outer iteration or centering point and a iteration of the newton algorithm within the centering step an inner iteration.

% notes on convergence rates:
% complexity analysis for self concordant functions. quad, lin. problems special case of s c fct.
% for non s c fct, reformulation to sc fvt possible
% function strictly convex and self-con. -> bound íon newton iterations dep. on tolerance, backtrack. param. f(x0)
% 11.25 ??
% bound for newton iteration in one outer step is not dependent on n or p or t!

\begin{algorithm}
		\SetAlgoLined
		\KwResult{$ \xoptt $, approximate solution of \eqref{eq:OptProblem} with $ \fnull(\xoptt) - \popt < \frac{m}{t} $ }
		initialization: Matrices $ 0 \prec Q\in \R^{n \times n}, c\in \Rn. $ defining the objective function, matrices $ \Aeq, \beq, \Aineq, \bineq $ defining constraints, initial point $ x $, initial approximation parameter $ t > 0 $, rate for increasing appprox. param. $ \mu > 1 $ tolerance $ \epsilon $ \todo dimensions of constr. matrices\\
		\While{$\frac{m}{t} \geq \epsilon$}{
			Compute $ \xoptt $ by solving $ \eqref{eq:ApproxProblem} $ via Newton's Method, starting at $ x $\;
			Update $ x := \xoptt $\;
			Increase $ t $ by $ t := \mu t $
%			\eIf{condition}{
%				instructions1\;
%				instructions2\;
%			}{
%				instructions3\;
%			}
		}
		\caption{Interior Point Method with full Newton search}
\end{algorithm}




\subsubsection{Primal-Dual Interior Point Method}
Like the previously introduced algorithm, the Primal-Dual Interior Point method uses the barrier concept to handle inequality constraints. It is motivated by the following idea. Since the points generated by each outer iteration converge to the desired optimum on the central path, one does not gain much advantage by computing the centralpoints with a high level of accuracy. So many newton-steps are computed, without improving the convergence towards the optimum value of \eqref{eq:OptProblem}. Hence, it would be useful to reduce the accuracy of each outer iteration as much as possible, without losing convergence to the optimum. Therefore, in this method only one newton step will be computed for each parameter $ t $ in the approximated problem  \eqref{eq:ApproxProblem}. Additionally, the Newton step is computed differently. While in the the search directions are computing only considering the primal problem, in the \pdm we also take the dual problem of\\
\todo write dual problem\\
problem \eqref{eq:ApproxProblem} into account. In particular Newton's method is applied to a system of residual terms, that have to equal all zero by the KKT-conditons\\
\todo KKT cond.
Stacked in one vector, this yields
\begin{align}
\begin{split}
	 F(x,\lambda,\nu) :&= \rmu = \vectorthree{\rdual}{\rcent}{\rpri}\\ &= \vectorthree{\grad \fnull(x) + \jac \fx \trp \lambda + \Aeq \trp \nu}{-\diag(\lambda)\fx - \mu \ones}{\Aeq x - \beq} = 0.
\end{split}
\end{align}
to apply Newton on. For formulation of the linear Newton equality, we also compute  the jacobian
\begin{align}
	\frac{\mathrm{d} \; ( \rmu)}{\mathrm{d} (x,\lambda,\nu)\trp} = 
	\begin{pmatrix}
		\hessfnull + \sum_{i = 1}^{m} \lambdai \hessfi & \jac \fx & \Aeq \trp\\
		-\diag(\lambda) \jac \fx & -\diag(\fx) & 0\\
		\Aeq & 0 & 0
	\end{pmatrix}
\end{align}
of the residual. 
Consequently, the Newton equality for finding the search direction $ \deltaxln $ in each newton step is exactly
\begin{align}
		\begin{pmatrix}
	\hessfnull + \sum_{i = 1}^{m} \lambdai \hessfi & \jac \fx & \Aeq \trp\\
	-\diag(\lambda) \jac \fx & -\diag(\fx) & 0\\
	\Aeq & 0 & 0
	\end{pmatrix} \vectorthree{\Delta x}{\Delta \lambda}{\Delta \nu} = - \vectorthree{\rdual}{\rcent}{\rpri}.
\end{align}(
\todo equality should fit in col.!\\

Unfortunately, adding the obtained step direction $ \deltaxln $ to $ (x,\lambda,\nu) $, does not in general yield a feasible point. Therefore we compute a suitable step-size $ \sopt $ via a backtracking-linesearch, such that a certain decrease of the residual and feasibility is guaranteed for the next iteration point \[ \vectorthree{\xplus}{\lambdaplus}{\nuplus} = \xlnvec + \sopt  \vectorthree{\Delta x}{\Delta  \lambda}{\Delta \nu}.\]

%TODO algo env undredstand
\todo understand algo env.
\begin{algorithm}
		\SetAlgoLined
		\KwResult{Stepsize $ \sopt $, s.t. $ \lambdaplus > 0  $ and $ r_\mu $ decreases by certain amount.  }
		initialization: Problem matrices, current $ x,\lambda,\nu $, Newton direction $ \Delta x,\Delta \lambda, \Delta \nu $, barrier parameter $ \mu $, backtracking parameters $ \alpha \geq 0, \beta \in (0,1) $. 
		Initial step-size $ \smax := \min \{ 1, \min_{i|\Delta \lambdai<0} -\lambdai / \Delta \lambdai \}$ \\
		
		
	%	\While{While condition}{
	%		instructions\;
	%		\eIf{condition}{
	%			instructions1\;
	%			instructions2\;
	%		}{
	%			instructions3\;
	%		}
	%	}
	%	\caption{Newton's Method}
\end{algorithm}





\subsection{Complexity Analysis Barrier Method}
\todo

\subsection{Newton's Method}
Newton's method is an iterative process to solve nonlinear equality systems
\begin{equation}
\Fx= 0
\end{equation}
for a differentiable map $ F: \Rn \longrightarrow \Rm $. The idea of this algorithm is as follows: At a given point $ \xk $, the zero of the linear approximation of $ F $ around $ \xk $  is computed. This point is chosen as the next iterate $ \xkplus $. In particular, a linear approximation of $ F $ in  $ \xk $ is defined as
\begin{equation}
	\Lx:= \Fxk + \jacFxk(x - \xk) \text{ for } x\in \Rn,
\end{equation}
where $ \jacFxk $ is the Jacobian of $ F $ at the point $ \xk $. If $ \jacFxk $ invertible, the point $ \xtil $ with $ L(\xtil)=0 $ is exactly the solution of  the linear equality $ \jacFxk x = -\Fx $.
%Though Newton's method is in general not guaranteed to converge,  
Technical conditions and proofs about convergence rates of Newton's method can be found in \cite{SO}.

%TODO Newton algo angeben??
%\begin{algorithm}
%	\SetAlgoLined
%	\KwResult{$ \xtil $, approximate solution of nonlinear system of equalities $ \Fx = 0$ }
%	initialization\; Function $ F: \Rn \longrightarrow \Rn $, initial point $ \xnull $\\
%	\While{While condition}{
%		instructions\;
%		\eIf{condition}{
%			instructions1\;
%			instructions2\;
%		}{
%			instructions3\;
%		}
%	}
%	\caption{Newton's Method}
%\end{algorithm}

For the purpose of optimizing a convex, twice differentiable objective function $ \fnull $ we want to find a zero of the gradient $ \grad \fnull $. Therefore we can apply the Newton Method to solve the non-linear equation \[ \Fx := \vectortwo{\grad \fnull (x)}{g(x)} = 0 \qquad \text{with }  g(x) = \vectorthree{g_1(x)}{\vdots}{g_p(x)} \]. By convexity, satisfying $ \grad \fnull (\xopt) = 0$ is not only neccessary, but also sufficient for $ \xopt $ to be a global minimum of $ \fnull $.

Present main theorems/algorithm. Explain idea, explain algorithm, 
provide a convergence proof, discuss main properties (advantages and disadvantages)
%\begin{algorithm}
%	
%\end{algorithm}
Use algorithm environment in Latex to present algorithm (pseudo-code)