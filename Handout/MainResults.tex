
\todo make $ \R $ prettier\\

\subsection{Newton's Method}
Newton's method is an iterative process to solve nonlinear equation systems
\begin{equation}
\Fx= 0
\end{equation}
for a differentiable map $ F: \Rn \longrightarrow \Rm $. The algorithm works as follows: At a given point $ \xk $, the zero of the linear approximation of $ F $ around $ \xk $  is computed. This point is chosen as the next iterate $ \xkplus $. In particular, a linear approximation of $ F $ in  $ \xk $ is defined as
\begin{equation}
\Lx:= \Fxk + \jacFxk(x - \xk) \text{ for } x\in \Rn,
\end{equation}
where $ \jacFxk $ is the Jacobian of $ F $ at the point $ \xk $. If $ \jacFxk $ is invertible, the point $ \xtil $ with $ L(\xtil)=0 $ is exactly the solution of  the linear equation $ \jacFxk x = -\Fx $.
%Though Newton's method is in general not guaranteed to converge,  
Technical conditions and proofs about convergence rates of Newton's method can be found in \cite{SO}.
The procedure executing a Newton search is summarized in \eqref{alg:newton}.

\begin{algorithm}
	\SetAlgoLined
	\KwResult{$ \xtil $, approximate solution of nonlinear system of equalities $ \Fx = 0$, residual tolerance $ \epsres >0$, cauchy-tolerance $ \epscauchy >0 $}
	\KwData{Function $ F: \Rn \longrightarrow \Rn $, initial point $ \xnull $}
	\BlankLine
	\While{$ \norm{x - \xlast} \geq \epscauchy $ or $ \norm{\Fx} \geq \epsres $}{
		compute Newton direction $ \Delta x $ by solving $ \jac F(x) \Delta x = -F(x) $\;
		remember last interation for checking term. crit. $ \xlast = x $\;
		update current point by $ x = x +  \Delta x$\;
	}
	return $ \tilde{x} = x $\;
	\caption{Newton's Method}
	\label{alg:newton}
\end{algorithm}
%\todo  newton decrement!!>?
%TODO
\begin{remark}\label{re:newtonStop}
	The residual and the cauchy-criterion for termination should be combined for the newton method. Easy examples are known, where one of the criteria is satisfied even though the current iteration is far from the optimal point. For details, see \cite{SO}.
	For theoretical reasoning, or if $ \grad^2 f(x)^{-1} $ can be used explicitely, one can also use the decreasement of $ \lambda^2 = \grad \fx \trp \grad^2 f(x)^{-1} \grad f(x)$ (so called newton-decrement) under a certain tolerance.
\end{remark}

For the purpose of optimizing a convex, twice differentiable objective function $ \fnull $ we want to find a zero of the gradient $ \grad \fnull $. Therefore we can apply the Newton Method to solve the non-linear equation \[ \Fx := \vectortwo{\grad \fnull (x)}{g(x)} = 0. \] By convexity, satisfying $ \grad \fnull (\xopt) = 0$ is not only neccessary, but also sufficient for $ \xopt $ to be a global minimum of $ \fnull $.\\


\subsection{Concept of Barrier Methods}
Convex optimization problems with no inequality constraints can  be solved efficiently by using Newton's method. If inequality constraints are involved, Newton's method can not guarantee feasibility of a found solution. Hence it is desirable, to transform an inequality-constrained optimization problem into one, that is only equality-constrained. Therefore, we move the inequality constraints implicitly to the objective function.
A simple and precise way to do this, would be to evaluate an  indicator function  
\begin{align}
	\ifct (x) :=
	\begin{cases}
		0 \quad &\text{for } u \neq 0\\
		\infty &\text{for } u > 0
	\end{cases}
\end{align}
on the values of the inequality constraints $ f_i, i=1,\dots,m $. We obtain a problem in the following shape
\begin{align}
	\begin{aligned}
	& \underset{x}{\text{minimize}}
	& & f_0(x) + \sum_{i=1}^{m} \ifct(f_i(x))\\
	& \text{subject to}
	& & \Aeq x - \beq = 0.
	\end{aligned} \label{eq:ifctProblem}
\end{align}
This problem is equivalent to \eqref{eq:OptProblem}, since it yields an objective value of $ +\infty  $ for every infeasible point while it is the same problem for every feasible one. We now have a formulation without inequality constraints. However, it is clearly neither convex nor continuous and hence not differentiable. Since we need these properties to solve the optimization problem computationally, we approximate the indicator function $ \ifct $ by the function
\begin{equation}
	\ifcthat (u) =
	\begin{cases}
	 \frac{1}{t}\log(-u) \quad \text{for } u < 0,\\
	 \infty \quad \text{for } u\geq 0,
	\end{cases}
\end{equation}
The parameter $ t>0 $ sets the approximation's accuracy. A higher value for $ t $ results in a better approximation of the indicator function.
By replacing the indicator function by $ \ifcthat $, we obtain an
%TODO evt plot von Ihat einfügen!100% 100
approximation 
\begin{equation}
\begin{aligned}
& \underset{x}{\text{minimize}}
& & f_0(x) - \sum_{i=1}^{m} \frac{1}{t} \log(-f_i(x)) \\
& \text{subject to}
& & \Aeq x - \beq = 0
\end{aligned} \label{eq:ApproxProblem}
\end{equation}
of problem \eqref{eq:OptProblem}. Throughout this paper, we denote its  Lagrangian by $ L_t: \Rn \times \Rp \longrightarrow \R $.

Note that $ \frac{1}{t}\log(-u) $ is convex, increasing in $ u $, and differentiable on the feasible set. Hence the entire function $ \sum_{i=1}^{m} \ifcthat(f_i(x)) $ is convex and \eqref{eq:ApproxProblem} is a convex Problem with differentiable objective function. These properties allow us to solve $ \eqref{eq:ApproxProblem} $ computationally.
We call an optimal point $ \xopt(t) $ of \eqref{eq:ApproxProblem} with parameter $ t $  a central point and a solution to its dual problem $ (\lambdaopt(t),\nuopt(t)) $ a dual central point. The set of (dual) solutions of \eqref{eq:ApproxProblem} for all $ t>0 $ we call the (dual) central path. Since for points $ x $ with $ f_i(x) = 0 $ for any $ x \in \{1,\dots,m \} $, the objective of \eqref{eq:ApproxProblem} is $ \infty $, all central points are in the interior of the set, satisfying the inequality constraints of \eqref{eq:OptProblem}. Thus this framework is named interior point method. One can show, that solutions $ (\xoptt,\lambdaoptt,\nuoptt) $ of \eqref{eq:ApproxProblem} converge to the solution  $ (\xopt,\lambdaopt, \nuopt) $ of \eqref{eq:OptProblem} for $ t  \longrightarrow 0 $. The proof can be found in \cite{BV}.
\label{sec:BarrierConcept}
\subsection{Measure for the Approximation's quality}
An immediately arising question is which conclusions about the solution $ (\xopt,\lambdaopt, \nuopt) $ of \eqref{eq:OptProblem} can be drawn from knowing a solution of $ \eqref{eq:ApproxProblem} $ for a certain $ t>0 $ about the value $ \fnull(\xoptt) $  of a central point $ \xoptt $, compared with the optimal value $ \popt $ of the original problem. 
For compactness, we denote the barrier term of the approximated problem as
\[ \phix = - \sum_{i=1}^{m} \log(-f_i(x)),\] with its Jacobian and Hessian being
\begin{align*}
	\grad \phix&= \gradphiexp,\\
	\grad^2 \phix &= \hessphiexp.
\end{align*}
For the sake of simplifying notation, throughout this section we consider the problem
\begin{equation}
	\ApproxOptProblemMultt \label{eq:ApproxProblemMult}
\end{equation}
that is obtained by multiplying the objective in \eqref{eq:ApproxProblem} with $ t>0 $. The original and the obtained problem are equvialent.
Any arbitrary $ \xoptt $ a strictly feasible point of \eqref{eq:OptProblem}. Since $ \xoptt $ solves \eqref{eq:ApproxProblemMult}, there exists $ \nuhat \in \Rp$, such that\\
%\todo define $ L_t $ as gradient for approx problem\\
\todo check consistency
\begin{align}
	\grad L_t(\xoptt, \nuhat) &= t \grad \fnull(\xoptt) + \grad \phi(\xoptt) + \Aeq \trp \nuhat\\
					&= t\grad f_0 (\xoptt) \notag\\&\quad+ \gradphiexpv{\xoptt} + \Aeq\trp \nuhat.\\&=0
					\label{eq:centralPathLagr}
\end{align}
holds. Note that  the Lagrangian only depends on $ (x,\nuhat) $, since there are no explicit inequality constraints involved. We keep in mind, that $ \xoptt $ minimizes \eqref{eq:ApproxProblem}.
Using this insight, we know that there exists a dual feasible point $ (\xoptt,\lambdaoptt, \nuoptt) $ of the original problem \eqref{eq:OptProblem}. In particular, we choose
\begin{gather*}
	\lambdaoptt = -\frac{1}{tf_i(\xoptt)}\text{ for }i=1,\dots,m,\quad \nuoptt= \frac{\nuhat}{t}.
\end{gather*}
Here, $ \lambdaoptt > 0 $ follows from $ f_i(\xopt) < 0 $ for all $ i = 1,\dots,m $ since $ \xopt  $ is strictly feasible.


Note that \eqref{eq:centralPathLagr} is the derivative of the Lagrangian 
\[ L(x,\lambda,\nu) = f_0(x) + \sum_{i=1}^{m}\lambdai^*(t) f_i(x) + \nuoptt \trp (\Aeq \xoptt - \beq) \]
 dividied by $ t>0 $ of the original problem.
The Lagrangian is convex in the first coordinate, hence we infer that $ \xoptt $ minimizes the Lagrangian  of the original problem for any fixed $ (\lambda,\nu) $.
For the dual function of the original problem, we obtain
\begin{align}
\begin{split}
	g(\lambdaoptt,\nuoptt) &= f_0(\xoptt) + \sum_{i=1}^{m} \lambdai^*(t) f_i(\xoptt))\\&\qquad+\nuoptt \trp (\Aeq \xoptt - \beq)\\ & = f_0(\xoptt) - \movert.
\end{split}
\end{align}
The second of the three summands adds up to $ m\cdot 1 $, because of the particular choice of $ \lambdaoptt $,  fractions cancel out. The last summand equals zero, since $ \Aeq \xoptt - \beq = 0$.




%OLD
%argumenting with the Lagrangian and the Saddlepoint-theorem, one can show that the inequality
%\[ \fnull (\xoptt) - \popt \leq \frac{m}{t}\] holds, where $ t $ is the parameter of the approximative indicator-function $ \ifcthat $ and $ m $ the number of inequality constraints as defined above.


By weak duality, this means that the optimum $ \xoptt $ of the approximated problem \eqref{eq:ApproxProblem} has an objective value $ \fnull(\xoptt) $ that is maximally larger  by $ \frac{m}{t} $ (and hence worse) than the real optimal value $ \popt $ of the original problem. Thus, one can theoretically force a desired bound on the subobtimality $ \epsilon >0 $ by choosing $ t $ large enough, in particular $ t := \frac{m}{\epsilon} $. However, just solving \eqref{eq:ApproxProblem} with a large choice of $ t $ does not work out in general, since numerical issues can make convergence of Newton's Method dependent on the choice of the initial point $ \xnull $.
\label{sec:approxMeasure}

\subsection{Algorithmic Use of the Barrier Concept}
As already mentioned in section \ref{sec:approxMeasure}, one can not solve  \eqref{eq:ApproxProblem} generally without a good guess of the initial value $ \xnull $. So how to make use of the barrier concept? The idea of interior methods is, to find points along the problem's central path. Two methods are introduced in the following. Emphasis of the explanations as well as the implementation in \matlab \ will be on the Primal-Dual Interior Point Method.
\subsubsection{Barrier Method}
As mentioned before, for large $ t $ a good initial point $ \xnull $, meaning an initial point that is not far away from the actual minimum of \eqref{eq:OptProblem}, is crucial for avoiding large numerical errors. This can be achieved by starting with optimization of \eqref{eq:ApproxProblem} for small $ t=t_1 $, which leads to a rather bad approximation of the original problem, but also to better numerical behavior. After finding $ \xopt(t_1) $ via Newton's method, $ t $ is increased to $ t= t_2 > t_1 $ by a certain rate and  \eqref{eq:ApproxProblem} is solved again with parameter $ t = t_2 $, with choice $ \xnull = \xopt(t_1) $ for the initial point.
%For step $ n $ of the algorithm call finding $ \xoptt $ the centering, or outer iteration, step of the algorithm and increasing $ t_n \mapsto t_{n+1} $ with setting $ \xnull :=  \xopt(t_n)$ an outer iteration.
%For step $ n $ of the algorithm call finding $ \xoptt $ the centering, and updating $ t $ and $ \xoptt $ an outer iteration or centering point and a iteration of the newton algorithm within the centering step an inner iteration. The whole procedure is written in Algorithm \ref{alg:BarrierFullNewton}.

We call finding the minimum $ \xoptt $ of  \eqref{eq:ApproxProblem} the centering step or outter iteration, while we call a single Newton step inside  the centering step an inner iteration.

% notes on convergence rates:
% complexity analysis for self concordant functions. quad, lin. problems special case of s c fct.
% for non s c fct, reformulation to sc fvt possible
% function strictly convex and self-con. -> bound íon newton iterations dep. on tolerance, backtrack. param. f(x0)
% 11.25 ??
% bound for newton iteration in one outer step is not dependent on n or p or t!

\begin{algorithm}
		\SetAlgoLined
%		\SetKwComment{bla}{abc}{keks}
		\KwResult{$ \xoptt $, approximate solution of \eqref{eq:OptProblem} with $ \fnull(\xoptt) - \popt < \frac{m}{t} $ }
		initialization: Matrices $ 0 \prec Q\in \R^{n \times n}, c\in \Rn. $ defining the objective function, matrices $ \Aeq\in \R^{m \times n} \beq\in \Rp, \Aineq\R^{m\times n}, \bineq\in \Rm $ defining constraints, initial point $ x $, initial approximation parameter $ t > 0 $, rate for increasing appprox. param. $ \mu > 1 $ tolerance $ \epsilon $\;
		\While{$\frac{m}{t} \geq \epsilon$}{
			Compute $ \xoptt $ by solving $ \eqref{eq:ApproxProblem} $ via Newton's Method, starting at $ x $\;
			Update $ x := \xoptt $\;
			Increase $ t $ by $ t := \mu t $
		}
		\caption{Barrier Method with full Newton search}
		\label{alg:BarrierFullNewton}
\end{algorithm}




\subsubsection{Primal-Dual Interior Point Method}
Like the previously introduced algorithm, the Primal-Dual Interior Point method uses the barrier concept to handle inequality constraints. It is motivated by the following idea: Since the points generated by each outer iteration converge to the desired optimum on the central path, one does not gain much advantage by computing the central points with a high level of accuracy. This results in many newton-steps being computed, without improving the convergence towards the optimum value of \eqref{eq:OptProblem}. Hence, it would be useful to reduce the accuracy of each outer iteration as much as possible, without losing convergence to the optimum. Therefore, in this method only one newton step will be computed for each parameter $ t $ in the approximated problem  \eqref{eq:ApproxProblem}. Furthermore, this Newton step is computed differently. While in the barrier method with full newton search,  the search directions are computed only considering the primal problem, the \pdm also takes the dual problem of \eqref{eq:ApproxProblem} into account. In particular Newton's method is applied to a system of residual terms, which all have to equal zero by the KKT-conditons, here presented like in \cite{BV}.\\
\begin{theorem}[KKT-Conditions for convex Problems]
	For a convex Optimization Problem \eqref{eq:OptProblem}, the following conditions on a primal-dual point $ (x,\lambda,\nu) \in \Rn \times \Rm \times \Rp$ are neccessary and sufficient for $ x $ being a solution to the primal problem and $ (\lambda, \nu) $ being a solution to the dual problem:
	\begin{subequations}
			\begin{align}
		f_i(x) &\leq 0, \quad \text{for } i = 1,\dots,m\\
		\Aeq x - \beq &= 0\\
		\lambda_i &\geq 0,  \quad \text{for } i = 1,\dots,m\\
		\lambdai f_i(x) & = 0, \quad \text{for } i = 0, \dots,m\\
		\grad \fnull(x) &+ \sum_{i=1}^{m} \lambdai \grad f_i(x) + \sum_{i=1}^{p} \nu_i \grad h_i (x) = 0.
		\end{align}
	\end{subequations}
\end{theorem}

Stacked in one vector, this yields the system of equalities
\begin{align}
\begin{split}
\label{eq:KKTres}
%	 F_t(x,\lambda,\nu) :&=
	 \rmu &= \vectorthree{\rdual}{\rcent}{\rpri} \\&= \vectorthree{\grad \fnull(x) + \jac \fx \trp \lambda + \Aeq \trp \nu}{-\diag(\lambda)\fx - \mu \ones}{\Aeq x - \beq} \overset{!}{=} 0.
\end{split}
\end{align}

to apply Newton's method on. For formulation of the linear Newton equality, we also compute  the jacobian
\begin{align}
%	\frac{\mathrm{d} \; ( \rmu)}{\mathrm{d} (x,\lambda,\nu)\trp}\\ &= 
	&\jac_{(x,\lambda,\nu)} \rmu\\ &= 
	\underbrace{\begin{pmatrix}
		\hessfnull + \sum_{i = 1}^{m} \lambdai \hessfi & \jac \fx & \Aeq \trp\\
		-\diag(\lambda) \jac \fx & -\diag(\fx) & 0\\
		\Aeq & 0 & 0
		\end{pmatrix}}_{:= \Mkkt}	
\end{align}
of the residual and refer to it as $ \Mkkt $. 
Consequently, the Newton equality for finding the search direction $ \deltaxln $ in each newton step is obtained by solving the linear equation
\begin{align}
\label{eq:rmuNewtonEq}
%		\begin{pmatrix}
%	\hessfnull + \sum_{i = 1}^{m} \lambdai \hessfi & \jac \fx & \Aeq \trp\\
%	-\diag(\lambda) \jac \fx & -\diag(\fx) & 0\\
%	\Aeq & 0 & 0
%	\end{pmatrix}
\Mkkt
	 \vectorthree{\Delta x}{\Delta \lambda}{\Delta \nu} = \bkkt
	 %\vectorthree{\rdual}{\rcent}{\rpri}.
\end{align}
with $ \bkkt = - \rmu. $

Unfortunately, adding the obtained step direction $ \deltaxln $ to $ (x,\lambda,\nu) $, does not in general yield a feasible point. Therefore we compute a suitable step-size $ \sopt $ via a backtracking-linesearch, such that a certain decrease of the residual and feasibility is guaranteed for the next iteration point \[ \vectorthree{\xplus}{\lambdaplus}{\nuplus} = \xlnvec + \sopt  \vectorthree{\Delta x}{\Delta  \lambda}{\Delta \nu}.\]
The detailed procedure of the backtracking linesearch is displayed in Algorithm \ref{alg:backtracking}.

\begin{algorithm}
		\SetAlgoLined
		\KwResult{Stepsize $ \sopt $, s.t. $ \lambdaplus > 0, f(\xplus) < 0  $ and $ r_\mu $ decreases by certain amount.  }
		\KwData{
		 Problem matrices, current $ x,\lambda,\nu $, Newton direction $ \Delta x,\Delta \lambda, \Delta \nu $, barrier parameter $ \mu $, backtracking parameters $ \alpha \geq 0, \beta \in (0,1) $. 
		Initial step-size set $ \smax = \min \{ 1, \min_{i|\Delta \lambdai<0} -\lambdai / \Delta \lambdai \}$ }
		\BlankLine
			compute $ \rmu $\;
			$ s = \smax $\;
			$ found = false $\;
		
		\While{$ found == false $}
		{		
				set $ s = \beta s $\;
				compute $ (\xplus,\lambdaplus,\nuplus) $\;
				compute $ r_\mu(\xplus, \lambdaplus,\nuplus)$ and $ f(\xplus) $\;
%				\If{$ f(\xplus) < 0 $ and  $ r_\mu(\xplus, \lambdaplus,\nuplus) \leq (1-\alpha s)  \norm{\rmu}$}{$found = true$}\;
	\If{$ f(\xplus) < 0 $ and $\norm{r_\mu(\xplus, \lambdaplus,\nuplus)} \leq (1-\alpha s)\norm{\rmu}  $ }{$ found = true $}
		}
		\caption{Backtracking linesearch}
		\label{alg:backtracking}
\end{algorithm}

Finally, we can present the entire algortithm of the \pdm.

\begin{algorithm}
		\SetAlgoLined
	\KwResult{approximate optimizer $ \xopthat $, approx. opt. value $ \popthat $, approx. dual optimizer $ (\lambdaopthat, \nuopthat) $, surrogate duality gap  $ \etaopthat $ as measure of optimality}
	\KwData{Problem matrices, primal-dual initial point $ (x,\lambda,\nu) $ with $ f_i(x)<0 $ for all $ i=1,\dots,m $, $ \lambda > 0, \nu \in \Rp $ (initial point strictly feasibile), reduction factor $ \gamma \in (0,1) $, tolerances $ \epsfeas, \epsopt > 0 $}
	\BlankLine
	
	Initialization\;
	determine problem dimensions $ n,m,p $\;
	set $ found=false $\;
	\BlankLine
	
	\While{$ found==false $}{
		compute surrogate duality gap: $ \etahat = - \fx \trp \lambda $\;
		compute KKT residual vector $ \rmu $ via \eqref{eq:KKTres}\;
		compute search direction $ (\Delta x, \Delta \lambda, \Delta \nu) $ by solving \eqref{eq:rmuNewtonEq}\;
		determine suitable step size $ s $ via backtracking algorithm  \ref{alg:backtracking}\;
		update current primal and dual points:
		$ (x,\lambda,\nu) = (x,\lambda,\nu) + (\Delta x, \Delta \lambda, \Delta \nu) $\;
	}
	return $ \xopthat = x, \popthat = f_0(\xopthat), \lambdaopthat = \lambda, \nuopthat = \nu, \etaopthat=\etahat $\;
	
	
	\caption{Primal-Dual Interior Point Method}
	\label{alg:pdip}
\end{algorithm}

\begin{remark}
	If a strictly feasible primal variable $ x \in \Rn $ is known, $ \lambda= -1/f_i(x) \geq 0, \nu=0 $ is always a valid choice for the initial dual variables.
\end{remark}
 
 
\subsection{How to find a feasible inital point}
The Algorithms \ref{alg:BarrierFullNewton} and \ref{alg:pdip} both need a strictly feasible initial point to start. Since such a point is in general not trivial to find, one can formulate the search for the initial point as another convex optimization problem, that is easier to solve than the original one.  
For problem \eqref{eq:OptProblem}, one way to implement this, is solving
\begin{equation}
	\OptProblemfeas
	\label{eq:feasProblem}
\end{equation}
via Newton's method. If a point with optimal value strictly smaller than zero for \eqref{eq:feasProblem} is found, then this point is strictly feasible. Solving such a first, more simple problem is called a Phase I problem. More examples of such problems can be found in \cite{BV}.


\subsection{Complexity Analysis for the Barrier Method}
Emphasis of this article is on implementation and idea of the algorithms, so we treat complexity analysis only by presenting results without proves. We keep this restricted to the barrier method with full newton search.  We discuss the time complexity of the barrier method, meaning the total number of newton steps needed to solve \eqref{eq:OptProblem}. 
An upper bound of these iterations can be proven for problems with objectives that are self-concordant. While linear and quadratic functions satisfy selfconcordance in general, any other convex optimization problem can be rewritten as a self-concordant one, so this condition is not very restrictive.
The upper bound
\begin{equation} % BV 9
	\frac{\fx - \popt}{\gamma} + c
\end{equation}
on the maximal number of newton iterations that is needed to get a newton decrement (see remark \ref{re:newtonStop}) smaller than $ \epsnt $, where $ c $ depends on $  \epsnt $ by $ \log_2 \log_2(1/\epsnt) $, $ \popt $ is the primal problem's  optimal value and $ \gamma $ depends on choice of the backtracking parameters $ \alpha, \beta $ with\[ \frac{1}{\gamma} = \frac{20-8\alpha}{\alpha \beta (1-2\alpha)^2}.\]
The derivation of this bound is shown in \cite{BV}, section 9.

One can further show that this bound holds uniformly for any parameter $ t $ for all problems \eqref{eq:ApproxProblem}.
 Since there are exactly \[ \ceil*{ \frac{\log(m/\epsilon t_0)}{\log \mu}} \] outer steps neccessary to solve  \eqref{eq:ApproxProblem} with inital parameter $ t=t_0  $ and tolerance $ \epsilon $, the entire barrier method needs maximally
 \[ N = \ceil*{\frac{\log(m/\epsilon t_0)}{\log \mu}}\left( \frac{m(\mu - 1 -\log \mu)}{\gamma} + c\right)  \]   inner newton iterations, where $ m $ denotes the number of inequality constraints on  \eqref{eq:ApproxProblem}. to yield a result with a suboptimality of $ \epsilon $ or smaller. Detailed reasoning can be found in \cite{BV}, section 11.5. 
% CV 11.5






%Present main theorems/algorithm. Explain idea, explain algorithm, 
%provide a convergence proof, discuss main properties (advantages and disadvantages)
%%\begin{algorithm}
%%	
%%\end{algorithm}
%Use algorithm environment in Latex to present algorithm (pseudo-code)